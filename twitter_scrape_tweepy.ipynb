{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "import code.auth_and_scrape as get_tweets\n",
    "import code.preparation as prep\n",
    "#import code.visualization as viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets.authenticate(key, key_secret, access, access_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to scrape a chosen amount of tweets with a chosen keyword and append to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Tweets added from this response:  900\n",
      "# of Tweets added from this response:  900\n",
      "# of Tweets added from this response:  900\n",
      "# of Tweets added from this response:  900\n",
      "# of Tweets added from this response:  900\n",
      "# of Tweets added from this response:  900\n",
      "# of Tweets added from this response:  900\n"
     ]
    }
   ],
   "source": [
    "get_tweets.scrape_and_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1462933594754670600</td>\n",
       "      <td>2021-11-22 23:58:43+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@DestinyTheGame all id like is to be at least ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462933098887266308</td>\n",
       "      <td>2021-11-22 23:56:45+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@DestinyTheGame Can someone please explain to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1462932969086087176</td>\n",
       "      <td>2021-11-22 23:56:14+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@techaftmidnight @GoogleStadia @DestinyTheGame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1462932844418842632</td>\n",
       "      <td>2021-11-22 23:55:44+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Going live in 5 minutes!! Let's go GOD SQUAD!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1462932760515985420</td>\n",
       "      <td>2021-11-22 23:55:24+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@A_dmg04 @DestinyTheGame Dear Eva, please brin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 created_at language  favorites  \\\n",
       "0  1462933594754670600  2021-11-22 23:58:43+00:00       en          0   \n",
       "1  1462933098887266308  2021-11-22 23:56:45+00:00       en          0   \n",
       "2  1462932969086087176  2021-11-22 23:56:14+00:00       en          1   \n",
       "3  1462932844418842632  2021-11-22 23:55:44+00:00       en          1   \n",
       "4  1462932760515985420  2021-11-22 23:55:24+00:00       en          0   \n",
       "\n",
       "   retweets                                               text  \n",
       "0         0  @DestinyTheGame all id like is to be at least ...  \n",
       "1         0  @DestinyTheGame Can someone please explain to ...  \n",
       "2         0  @techaftmidnight @GoogleStadia @DestinyTheGame...  \n",
       "3         0  Going live in 5 minutes!! Let's go GOD SQUAD!!...  \n",
       "4         0  @A_dmg04 @DestinyTheGame Dear Eva, please brin...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6300.000000\n",
       "mean        9.520635\n",
       "std        90.900910\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max      3879.000000\n",
       "Name: favorites, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.favorites.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@DestinyTheGame Can someone please explain to me why I (top 7-10%ish player) keep getting teamed with people in the… https://t.co/fREoFm7Emb'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tweet has a ton of punctuation and it even includes a url. In order for our sentiment analyzer to read and understand this, we must remove the all of this and even lowercase every letter. Here A function has been create to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep.clean_tweets(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create a Sentiment Analysis using TextBlob and SentimentIntensityAnalyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs = prep.create_sentiment(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering Positive Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_uncleaned = prep.create_pos_df(df, df_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_cleaned = prep.clean_tweets(df_pos_uncleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['destiny2', 'threadsoflight', 'game', 'play', 'congrats', 'thanks', 'bring', 'destinythegame', 'make', 'really', 'don', 'hope', 'great', 'time', 'nice', 'better', 'new', 'day', 'playing', 'looks', 'congratulations', 'yeah', 'bungie', 'know', 'happy', 'trials', 'help', 'awesome', 'think', 've', 'going', 'dawning', 'wish', 'year', 'fun', 'got', 'space', 'hunter', 'people', 'shader', 'look', 'best', 'd2', 'live', 'crow', 'grandma', 'free', 'let', 'need', 'amazing', 'today', 'twab', 'friends', 'll', 'guardian', 'lol', 'week', 'use', 'getting', 'god', 'cool', 'pvp', 'changes', 'work', 'come', 'double', 'amp', 'right', 'looking', 'titan', 'team', 'maybe', 'ability', 'actually', 'oh', 'win', 'vex', 'pretty', 'flawless', 'thememe', 'super', 'man', 'played', 'rewards']\n"
     ]
    }
   ],
   "source": [
    "positives_and_count, pos_vec = prep.top_n_gram(df_pos_cleaned['clean_text'], (1,1), 300)\n",
    "\n",
    "positives = [x[0] for x in positives_and_count]\n",
    "top_10_pos = positives[:10]\n",
    "positives_minus_top_10 = [x for x in positives if x not in top_10_pos]\n",
    "print(positives_minus_top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (prep.create_features(review, positives_minus_top_10))\n",
    "    for review in df['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.concat([df['clean_text'], pd.DataFrame(features,columns=['positive_word_count'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>positive_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>read my mind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>oh god please no more cookie baking please</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>ahh   thanks so much  ghaul  lt 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>these cool down changes in combination with da...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>they talking about why eris had to put her r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>getting back into sniping   slowly         des...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>congratulations    hell yeah</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>ab you have been having problems for years...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>dear eva   could you kindly ask ada 1 to sel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>true  i haven t seen one either   i m exci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  positive_word_count\n",
       "4319                                       read my mind                    0\n",
       "518         oh god please no more cookie baking please                     2\n",
       "4584                  ahh   thanks so much  ghaul  lt 3                    1\n",
       "3768  these cool down changes in combination with da...                    2\n",
       "2990    they talking about why eris had to put her r...                    1\n",
       "...                                                 ...                  ...\n",
       "905   getting back into sniping   slowly         des...                    3\n",
       "5192                      congratulations    hell yeah                     2\n",
       "3980      ab you have been having problems for years...                    0\n",
       "235     dear eva   could you kindly ask ada 1 to sel...                    0\n",
       "5157      true  i haven t seen one either   i m exci...                    0\n",
       "\n",
       "[4725 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_feat, df_probs['sentiment'],random_state=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, feat_vec_train = prep.top_n_gram(X_train['clean_text'], (1,1), 100)\n",
    "feat, feat_vec_test = prep.top_n_gram_test(X_test['clean_text'], X_train['clean_text'], (1,1), 100)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Create X_train vectorized\n",
    "X_train_vec = pd.concat([X_train['positive_word_count'], pd.DataFrame(feat_vec_train.todense())], axis=1)\n",
    "X_test_vec = pd.concat([X_test['positive_word_count'], pd.DataFrame(feat_vec_test.todense())], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model is a simple logistic regression that scored 78% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873015873015873"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train_vec, y_train)\n",
    "log_model.score(X_test_vec, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c94be41889154d41bf43aca8d1a8d1cd64b97c119170e03e2ed46ca87183f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
